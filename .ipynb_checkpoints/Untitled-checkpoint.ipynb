{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406c18ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanm0a/anaconda3/envs/tfuse/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/fanm0a/anaconda3/envs/tfuse/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/fanm0a/anaconda3/envs/tfuse/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541035/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 7649612\n",
      "+-----------------------------------------------------+------------+\n",
      "|                       Modules                       | Parameters |\n",
      "+-----------------------------------------------------+------------+\n",
      "|         encoder.image_encoder_stem.0.weight         |    864     |\n",
      "|         encoder.image_encoder_stem.1.weight         |     32     |\n",
      "|          encoder.image_encoder_stem.1.bias          |     32     |\n",
      "|   encoder.image_encoder_layer1.0.block.0.0.weight   |    288     |\n",
      "|   encoder.image_encoder_layer1.0.block.0.1.weight   |     32     |\n",
      "|    encoder.image_encoder_layer1.0.block.0.1.bias    |     32     |\n",
      "|  encoder.image_encoder_layer1.0.block.1.fc1.weight  |    256     |\n",
      "|   encoder.image_encoder_layer1.0.block.1.fc1.bias   |     8      |\n",
      "|  encoder.image_encoder_layer1.0.block.1.fc2.weight  |    256     |\n",
      "|   encoder.image_encoder_layer1.0.block.1.fc2.bias   |     32     |\n",
      "|   encoder.image_encoder_layer1.0.block.2.0.weight   |    512     |\n",
      "|   encoder.image_encoder_layer1.0.block.2.1.weight   |     16     |\n",
      "|    encoder.image_encoder_layer1.0.block.2.1.bias    |     16     |\n",
      "|   encoder.image_encoder_layer2.0.block.0.0.weight   |    1536    |\n",
      "|   encoder.image_encoder_layer2.0.block.0.1.weight   |     96     |\n",
      "|    encoder.image_encoder_layer2.0.block.0.1.bias    |     96     |\n",
      "|   encoder.image_encoder_layer2.0.block.1.0.weight   |    864     |\n",
      "|   encoder.image_encoder_layer2.0.block.1.1.weight   |     96     |\n",
      "|    encoder.image_encoder_layer2.0.block.1.1.bias    |     96     |\n",
      "|  encoder.image_encoder_layer2.0.block.2.fc1.weight  |    384     |\n",
      "|   encoder.image_encoder_layer2.0.block.2.fc1.bias   |     4      |\n",
      "|  encoder.image_encoder_layer2.0.block.2.fc2.weight  |    384     |\n",
      "|   encoder.image_encoder_layer2.0.block.2.fc2.bias   |     96     |\n",
      "|   encoder.image_encoder_layer2.0.block.3.0.weight   |    2304    |\n",
      "|   encoder.image_encoder_layer2.0.block.3.1.weight   |     24     |\n",
      "|    encoder.image_encoder_layer2.0.block.3.1.bias    |     24     |\n",
      "|   encoder.image_encoder_layer2.1.block.0.0.weight   |    3456    |\n",
      "|   encoder.image_encoder_layer2.1.block.0.1.weight   |    144     |\n",
      "|    encoder.image_encoder_layer2.1.block.0.1.bias    |    144     |\n",
      "|   encoder.image_encoder_layer2.1.block.1.0.weight   |    1296    |\n",
      "|   encoder.image_encoder_layer2.1.block.1.1.weight   |    144     |\n",
      "|    encoder.image_encoder_layer2.1.block.1.1.bias    |    144     |\n",
      "|  encoder.image_encoder_layer2.1.block.2.fc1.weight  |    864     |\n",
      "|   encoder.image_encoder_layer2.1.block.2.fc1.bias   |     6      |\n",
      "|  encoder.image_encoder_layer2.1.block.2.fc2.weight  |    864     |\n",
      "|   encoder.image_encoder_layer2.1.block.2.fc2.bias   |    144     |\n",
      "|   encoder.image_encoder_layer2.1.block.3.0.weight   |    3456    |\n",
      "|   encoder.image_encoder_layer2.1.block.3.1.weight   |     24     |\n",
      "|    encoder.image_encoder_layer2.1.block.3.1.bias    |     24     |\n",
      "|   encoder.image_encoder_layer3.0.block.0.0.weight   |    3456    |\n",
      "|   encoder.image_encoder_layer3.0.block.0.1.weight   |    144     |\n",
      "|    encoder.image_encoder_layer3.0.block.0.1.bias    |    144     |\n",
      "|   encoder.image_encoder_layer3.0.block.1.0.weight   |    3600    |\n",
      "|   encoder.image_encoder_layer3.0.block.1.1.weight   |    144     |\n",
      "|    encoder.image_encoder_layer3.0.block.1.1.bias    |    144     |\n",
      "|  encoder.image_encoder_layer3.0.block.2.fc1.weight  |    864     |\n",
      "|   encoder.image_encoder_layer3.0.block.2.fc1.bias   |     6      |\n",
      "|  encoder.image_encoder_layer3.0.block.2.fc2.weight  |    864     |\n",
      "|   encoder.image_encoder_layer3.0.block.2.fc2.bias   |    144     |\n",
      "|   encoder.image_encoder_layer3.0.block.3.0.weight   |    5760    |\n",
      "|   encoder.image_encoder_layer3.0.block.3.1.weight   |     40     |\n",
      "|    encoder.image_encoder_layer3.0.block.3.1.bias    |     40     |\n",
      "|   encoder.image_encoder_layer3.1.block.0.0.weight   |    9600    |\n",
      "|   encoder.image_encoder_layer3.1.block.0.1.weight   |    240     |\n",
      "|    encoder.image_encoder_layer3.1.block.0.1.bias    |    240     |\n",
      "|   encoder.image_encoder_layer3.1.block.1.0.weight   |    6000    |\n",
      "|   encoder.image_encoder_layer3.1.block.1.1.weight   |    240     |\n",
      "|    encoder.image_encoder_layer3.1.block.1.1.bias    |    240     |\n",
      "|  encoder.image_encoder_layer3.1.block.2.fc1.weight  |    2400    |\n",
      "|   encoder.image_encoder_layer3.1.block.2.fc1.bias   |     10     |\n",
      "|  encoder.image_encoder_layer3.1.block.2.fc2.weight  |    2400    |\n",
      "|   encoder.image_encoder_layer3.1.block.2.fc2.bias   |    240     |\n",
      "|   encoder.image_encoder_layer3.1.block.3.0.weight   |    9600    |\n",
      "|   encoder.image_encoder_layer3.1.block.3.1.weight   |     40     |\n",
      "|    encoder.image_encoder_layer3.1.block.3.1.bias    |     40     |\n",
      "|   encoder.image_encoder_layer4.0.block.0.0.weight   |    9600    |\n",
      "|   encoder.image_encoder_layer4.0.block.0.1.weight   |    240     |\n",
      "|    encoder.image_encoder_layer4.0.block.0.1.bias    |    240     |\n",
      "|   encoder.image_encoder_layer4.0.block.1.0.weight   |    2160    |\n",
      "|   encoder.image_encoder_layer4.0.block.1.1.weight   |    240     |\n",
      "|    encoder.image_encoder_layer4.0.block.1.1.bias    |    240     |\n",
      "|  encoder.image_encoder_layer4.0.block.2.fc1.weight  |    2400    |\n",
      "|   encoder.image_encoder_layer4.0.block.2.fc1.bias   |     10     |\n",
      "|  encoder.image_encoder_layer4.0.block.2.fc2.weight  |    2400    |\n",
      "|   encoder.image_encoder_layer4.0.block.2.fc2.bias   |    240     |\n",
      "|   encoder.image_encoder_layer4.0.block.3.0.weight   |   19200    |\n",
      "|   encoder.image_encoder_layer4.0.block.3.1.weight   |     80     |\n",
      "|    encoder.image_encoder_layer4.0.block.3.1.bias    |     80     |\n",
      "|   encoder.image_encoder_layer4.1.block.0.0.weight   |   38400    |\n",
      "|   encoder.image_encoder_layer4.1.block.0.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer4.1.block.0.1.bias    |    480     |\n",
      "|   encoder.image_encoder_layer4.1.block.1.0.weight   |    4320    |\n",
      "|   encoder.image_encoder_layer4.1.block.1.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer4.1.block.1.1.bias    |    480     |\n",
      "|  encoder.image_encoder_layer4.1.block.2.fc1.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer4.1.block.2.fc1.bias   |     20     |\n",
      "|  encoder.image_encoder_layer4.1.block.2.fc2.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer4.1.block.2.fc2.bias   |    480     |\n",
      "|   encoder.image_encoder_layer4.1.block.3.0.weight   |   38400    |\n",
      "|   encoder.image_encoder_layer4.1.block.3.1.weight   |     80     |\n",
      "|    encoder.image_encoder_layer4.1.block.3.1.bias    |     80     |\n",
      "|   encoder.image_encoder_layer4.2.block.0.0.weight   |   38400    |\n",
      "|   encoder.image_encoder_layer4.2.block.0.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer4.2.block.0.1.bias    |    480     |\n",
      "|   encoder.image_encoder_layer4.2.block.1.0.weight   |    4320    |\n",
      "|   encoder.image_encoder_layer4.2.block.1.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer4.2.block.1.1.bias    |    480     |\n",
      "|  encoder.image_encoder_layer4.2.block.2.fc1.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer4.2.block.2.fc1.bias   |     20     |\n",
      "|  encoder.image_encoder_layer4.2.block.2.fc2.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer4.2.block.2.fc2.bias   |    480     |\n",
      "|   encoder.image_encoder_layer4.2.block.3.0.weight   |   38400    |\n",
      "|   encoder.image_encoder_layer4.2.block.3.1.weight   |     80     |\n",
      "|    encoder.image_encoder_layer4.2.block.3.1.bias    |     80     |\n",
      "|   encoder.image_encoder_layer5.0.block.0.0.weight   |   38400    |\n",
      "|   encoder.image_encoder_layer5.0.block.0.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer5.0.block.0.1.bias    |    480     |\n",
      "|   encoder.image_encoder_layer5.0.block.1.0.weight   |   12000    |\n",
      "|   encoder.image_encoder_layer5.0.block.1.1.weight   |    480     |\n",
      "|    encoder.image_encoder_layer5.0.block.1.1.bias    |    480     |\n",
      "|  encoder.image_encoder_layer5.0.block.2.fc1.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer5.0.block.2.fc1.bias   |     20     |\n",
      "|  encoder.image_encoder_layer5.0.block.2.fc2.weight  |    9600    |\n",
      "|   encoder.image_encoder_layer5.0.block.2.fc2.bias   |    480     |\n",
      "|   encoder.image_encoder_layer5.0.block.3.0.weight   |   53760    |\n",
      "|   encoder.image_encoder_layer5.0.block.3.1.weight   |    112     |\n",
      "|    encoder.image_encoder_layer5.0.block.3.1.bias    |    112     |\n",
      "|   encoder.image_encoder_layer5.1.block.0.0.weight   |   75264    |\n",
      "|   encoder.image_encoder_layer5.1.block.0.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer5.1.block.0.1.bias    |    672     |\n",
      "|   encoder.image_encoder_layer5.1.block.1.0.weight   |   16800    |\n",
      "|   encoder.image_encoder_layer5.1.block.1.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer5.1.block.1.1.bias    |    672     |\n",
      "|  encoder.image_encoder_layer5.1.block.2.fc1.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer5.1.block.2.fc1.bias   |     28     |\n",
      "|  encoder.image_encoder_layer5.1.block.2.fc2.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer5.1.block.2.fc2.bias   |    672     |\n",
      "|   encoder.image_encoder_layer5.1.block.3.0.weight   |   75264    |\n",
      "|   encoder.image_encoder_layer5.1.block.3.1.weight   |    112     |\n",
      "|    encoder.image_encoder_layer5.1.block.3.1.bias    |    112     |\n",
      "|   encoder.image_encoder_layer5.2.block.0.0.weight   |   75264    |\n",
      "|   encoder.image_encoder_layer5.2.block.0.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer5.2.block.0.1.bias    |    672     |\n",
      "|   encoder.image_encoder_layer5.2.block.1.0.weight   |   16800    |\n",
      "|   encoder.image_encoder_layer5.2.block.1.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer5.2.block.1.1.bias    |    672     |\n",
      "|  encoder.image_encoder_layer5.2.block.2.fc1.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer5.2.block.2.fc1.bias   |     28     |\n",
      "|  encoder.image_encoder_layer5.2.block.2.fc2.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer5.2.block.2.fc2.bias   |    672     |\n",
      "|   encoder.image_encoder_layer5.2.block.3.0.weight   |   75264    |\n",
      "|   encoder.image_encoder_layer5.2.block.3.1.weight   |    112     |\n",
      "|    encoder.image_encoder_layer5.2.block.3.1.bias    |    112     |\n",
      "|   encoder.image_encoder_layer6.0.block.0.0.weight   |   75264    |\n",
      "|   encoder.image_encoder_layer6.0.block.0.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer6.0.block.0.1.bias    |    672     |\n",
      "|   encoder.image_encoder_layer6.0.block.1.0.weight   |   16800    |\n",
      "|   encoder.image_encoder_layer6.0.block.1.1.weight   |    672     |\n",
      "|    encoder.image_encoder_layer6.0.block.1.1.bias    |    672     |\n",
      "|  encoder.image_encoder_layer6.0.block.2.fc1.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer6.0.block.2.fc1.bias   |     28     |\n",
      "|  encoder.image_encoder_layer6.0.block.2.fc2.weight  |   18816    |\n",
      "|   encoder.image_encoder_layer6.0.block.2.fc2.bias   |    672     |\n",
      "|   encoder.image_encoder_layer6.0.block.3.0.weight   |   129024   |\n",
      "|   encoder.image_encoder_layer6.0.block.3.1.weight   |    192     |\n",
      "|    encoder.image_encoder_layer6.0.block.3.1.bias    |    192     |\n",
      "|   encoder.image_encoder_layer6.1.block.0.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.1.block.0.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.1.block.0.1.bias    |    1152    |\n",
      "|   encoder.image_encoder_layer6.1.block.1.0.weight   |   28800    |\n",
      "|   encoder.image_encoder_layer6.1.block.1.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.1.block.1.1.bias    |    1152    |\n",
      "|  encoder.image_encoder_layer6.1.block.2.fc1.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.1.block.2.fc1.bias   |     48     |\n",
      "|  encoder.image_encoder_layer6.1.block.2.fc2.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.1.block.2.fc2.bias   |    1152    |\n",
      "|   encoder.image_encoder_layer6.1.block.3.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.1.block.3.1.weight   |    192     |\n",
      "|    encoder.image_encoder_layer6.1.block.3.1.bias    |    192     |\n",
      "|   encoder.image_encoder_layer6.2.block.0.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.2.block.0.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.2.block.0.1.bias    |    1152    |\n",
      "|   encoder.image_encoder_layer6.2.block.1.0.weight   |   28800    |\n",
      "|   encoder.image_encoder_layer6.2.block.1.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.2.block.1.1.bias    |    1152    |\n",
      "|  encoder.image_encoder_layer6.2.block.2.fc1.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.2.block.2.fc1.bias   |     48     |\n",
      "|  encoder.image_encoder_layer6.2.block.2.fc2.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.2.block.2.fc2.bias   |    1152    |\n",
      "|   encoder.image_encoder_layer6.2.block.3.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.2.block.3.1.weight   |    192     |\n",
      "|    encoder.image_encoder_layer6.2.block.3.1.bias    |    192     |\n",
      "|   encoder.image_encoder_layer6.3.block.0.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.3.block.0.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.3.block.0.1.bias    |    1152    |\n",
      "|   encoder.image_encoder_layer6.3.block.1.0.weight   |   28800    |\n",
      "|   encoder.image_encoder_layer6.3.block.1.1.weight   |    1152    |\n",
      "|    encoder.image_encoder_layer6.3.block.1.1.bias    |    1152    |\n",
      "|  encoder.image_encoder_layer6.3.block.2.fc1.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.3.block.2.fc1.bias   |     48     |\n",
      "|  encoder.image_encoder_layer6.3.block.2.fc2.weight  |   55296    |\n",
      "|   encoder.image_encoder_layer6.3.block.2.fc2.bias   |    1152    |\n",
      "|   encoder.image_encoder_layer6.3.block.3.0.weight   |   221184   |\n",
      "|   encoder.image_encoder_layer6.3.block.3.1.weight   |    192     |\n",
      "|    encoder.image_encoder_layer6.3.block.3.1.bias    |    192     |\n",
      "|               encoder.vel_emb1.weight               |     48     |\n",
      "|                encoder.vel_emb1.bias                |     24     |\n",
      "|               encoder.vel_emb2.weight               |    960     |\n",
      "|                encoder.vel_emb2.bias                |     40     |\n",
      "|               encoder.vel_emb3.weight               |    3200    |\n",
      "|                encoder.vel_emb3.bias                |     80     |\n",
      "|               encoder.vel_emb4.weight               |   15360    |\n",
      "|                encoder.vel_emb4.bias                |    192     |\n",
      "|               encoder.transformer1.ape              |   12000    |\n",
      "|      encoder.transformer1.blocks.0.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.0.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.0.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.0.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.0.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.0.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.0.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.0.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.0.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.0.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.0.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.0.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.0.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.0.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.0.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.0.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.0.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.1.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.1.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.1.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.1.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.1.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.1.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.1.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.1.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.1.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.1.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.1.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.1.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.1.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.1.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.1.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.1.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.1.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.2.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.2.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.2.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.2.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.2.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.2.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.2.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.2.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.2.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.2.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.2.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.2.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.2.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.2.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.2.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.2.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.2.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.3.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.3.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.3.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.3.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.3.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.3.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.3.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.3.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.3.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.3.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.3.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.3.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.3.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.3.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.3.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.3.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.3.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.4.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.4.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.4.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.4.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.4.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.4.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.4.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.4.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.4.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.4.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.4.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.4.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.4.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.4.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.4.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.4.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.4.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.5.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.5.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.5.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.5.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.5.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.5.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.5.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.5.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.5.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.5.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.5.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.5.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.5.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.5.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.5.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.5.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.5.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.6.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.6.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.6.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.6.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.6.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.6.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.6.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.6.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.6.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.6.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.6.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.6.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.6.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.6.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.6.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.6.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.6.mlp.fc2.bias     |     24     |\n",
      "|      encoder.transformer1.blocks.7.norm1.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.7.norm1.bias      |     24     |\n",
      "|    encoder.transformer1.blocks.7.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer1.blocks.7.attn.q_bias      |     24     |\n",
      "|      encoder.transformer1.blocks.7.attn.v_bias      |     24     |\n",
      "| encoder.transformer1.blocks.7.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer1.blocks.7.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer1.blocks.7.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer1.blocks.7.attn.qkv.weight    |    1728    |\n",
      "|    encoder.transformer1.blocks.7.attn.proj.weight   |    576     |\n",
      "|     encoder.transformer1.blocks.7.attn.proj.bias    |     24     |\n",
      "|      encoder.transformer1.blocks.7.norm2.weight     |     24     |\n",
      "|       encoder.transformer1.blocks.7.norm2.bias      |     24     |\n",
      "|     encoder.transformer1.blocks.7.mlp.fc1.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.7.mlp.fc1.bias     |     96     |\n",
      "|     encoder.transformer1.blocks.7.mlp.fc2.weight    |    2304    |\n",
      "|      encoder.transformer1.blocks.7.mlp.fc2.bias     |     24     |\n",
      "|               encoder.transformer2.ape              |   20000    |\n",
      "|      encoder.transformer2.blocks.0.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.0.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.0.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.0.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.0.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.0.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.0.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.0.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.0.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.0.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.0.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.0.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.0.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.0.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.0.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.0.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.0.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.1.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.1.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.1.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.1.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.1.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.1.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.1.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.1.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.1.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.1.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.1.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.1.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.1.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.1.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.1.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.1.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.1.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.2.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.2.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.2.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.2.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.2.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.2.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.2.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.2.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.2.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.2.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.2.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.2.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.2.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.2.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.2.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.2.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.2.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.3.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.3.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.3.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.3.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.3.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.3.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.3.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.3.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.3.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.3.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.3.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.3.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.3.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.3.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.3.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.3.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.3.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.4.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.4.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.4.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.4.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.4.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.4.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.4.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.4.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.4.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.4.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.4.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.4.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.4.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.4.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.4.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.4.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.4.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.5.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.5.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.5.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.5.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.5.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.5.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.5.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.5.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.5.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.5.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.5.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.5.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.5.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.5.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.5.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.5.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.5.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.6.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.6.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.6.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.6.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.6.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.6.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.6.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.6.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.6.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.6.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.6.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.6.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.6.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.6.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.6.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.6.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.6.mlp.fc2.bias     |     40     |\n",
      "|      encoder.transformer2.blocks.7.norm1.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.7.norm1.bias      |     40     |\n",
      "|    encoder.transformer2.blocks.7.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer2.blocks.7.attn.q_bias      |     40     |\n",
      "|      encoder.transformer2.blocks.7.attn.v_bias      |     40     |\n",
      "| encoder.transformer2.blocks.7.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer2.blocks.7.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer2.blocks.7.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer2.blocks.7.attn.qkv.weight    |    4800    |\n",
      "|    encoder.transformer2.blocks.7.attn.proj.weight   |    1600    |\n",
      "|     encoder.transformer2.blocks.7.attn.proj.bias    |     40     |\n",
      "|      encoder.transformer2.blocks.7.norm2.weight     |     40     |\n",
      "|       encoder.transformer2.blocks.7.norm2.bias      |     40     |\n",
      "|     encoder.transformer2.blocks.7.mlp.fc1.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.7.mlp.fc1.bias     |    160     |\n",
      "|     encoder.transformer2.blocks.7.mlp.fc2.weight    |    6400    |\n",
      "|      encoder.transformer2.blocks.7.mlp.fc2.bias     |     40     |\n",
      "|               encoder.transformer3.ape              |   40000    |\n",
      "|      encoder.transformer3.blocks.0.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.0.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.0.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.0.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.0.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.0.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.0.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.0.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.0.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.0.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.0.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.0.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.0.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.0.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.0.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.0.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.0.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.1.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.1.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.1.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.1.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.1.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.1.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.1.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.1.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.1.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.1.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.1.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.1.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.1.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.1.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.1.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.1.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.1.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.2.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.2.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.2.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.2.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.2.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.2.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.2.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.2.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.2.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.2.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.2.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.2.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.2.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.2.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.2.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.2.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.2.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.3.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.3.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.3.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.3.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.3.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.3.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.3.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.3.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.3.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.3.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.3.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.3.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.3.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.3.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.3.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.3.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.3.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.4.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.4.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.4.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.4.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.4.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.4.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.4.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.4.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.4.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.4.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.4.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.4.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.4.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.4.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.4.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.4.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.4.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.5.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.5.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.5.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.5.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.5.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.5.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.5.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.5.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.5.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.5.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.5.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.5.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.5.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.5.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.5.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.5.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.5.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.6.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.6.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.6.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.6.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.6.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.6.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.6.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.6.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.6.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.6.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.6.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.6.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.6.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.6.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.6.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.6.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.6.mlp.fc2.bias     |     80     |\n",
      "|      encoder.transformer3.blocks.7.norm1.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.7.norm1.bias      |     80     |\n",
      "|    encoder.transformer3.blocks.7.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer3.blocks.7.attn.q_bias      |     80     |\n",
      "|      encoder.transformer3.blocks.7.attn.v_bias      |     80     |\n",
      "| encoder.transformer3.blocks.7.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer3.blocks.7.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer3.blocks.7.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer3.blocks.7.attn.qkv.weight    |   19200    |\n",
      "|    encoder.transformer3.blocks.7.attn.proj.weight   |    6400    |\n",
      "|     encoder.transformer3.blocks.7.attn.proj.bias    |     80     |\n",
      "|      encoder.transformer3.blocks.7.norm2.weight     |     80     |\n",
      "|       encoder.transformer3.blocks.7.norm2.bias      |     80     |\n",
      "|     encoder.transformer3.blocks.7.mlp.fc1.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.7.mlp.fc1.bias     |    320     |\n",
      "|     encoder.transformer3.blocks.7.mlp.fc2.weight    |   25600    |\n",
      "|      encoder.transformer3.blocks.7.mlp.fc2.bias     |     80     |\n",
      "|               encoder.transformer4.ape              |   96000    |\n",
      "|      encoder.transformer4.blocks.0.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.0.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.0.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.0.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.0.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.0.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.0.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.0.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.0.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.0.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.0.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.0.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.0.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.0.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.0.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.0.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.0.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.1.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.1.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.1.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.1.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.1.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.1.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.1.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.1.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.1.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.1.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.1.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.1.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.1.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.1.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.1.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.1.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.1.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.2.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.2.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.2.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.2.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.2.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.2.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.2.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.2.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.2.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.2.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.2.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.2.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.2.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.2.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.2.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.2.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.2.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.3.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.3.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.3.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.3.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.3.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.3.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.3.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.3.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.3.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.3.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.3.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.3.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.3.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.3.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.3.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.3.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.3.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.4.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.4.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.4.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.4.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.4.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.4.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.4.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.4.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.4.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.4.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.4.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.4.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.4.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.4.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.4.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.4.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.4.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.5.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.5.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.5.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.5.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.5.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.5.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.5.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.5.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.5.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.5.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.5.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.5.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.5.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.5.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.5.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.5.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.5.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.6.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.6.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.6.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.6.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.6.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.6.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.6.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.6.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.6.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.6.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.6.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.6.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.6.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.6.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.6.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.6.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.6.mlp.fc2.bias     |    192     |\n",
      "|      encoder.transformer4.blocks.7.norm1.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.7.norm1.bias      |    192     |\n",
      "|    encoder.transformer4.blocks.7.attn.logit_scale   |     4      |\n",
      "|      encoder.transformer4.blocks.7.attn.q_bias      |    192     |\n",
      "|      encoder.transformer4.blocks.7.attn.v_bias      |    192     |\n",
      "| encoder.transformer4.blocks.7.attn.cpb_mlp.0.weight |    1024    |\n",
      "|  encoder.transformer4.blocks.7.attn.cpb_mlp.0.bias  |    512     |\n",
      "| encoder.transformer4.blocks.7.attn.cpb_mlp.2.weight |    2048    |\n",
      "|    encoder.transformer4.blocks.7.attn.qkv.weight    |   110592   |\n",
      "|    encoder.transformer4.blocks.7.attn.proj.weight   |   36864    |\n",
      "|     encoder.transformer4.blocks.7.attn.proj.bias    |    192     |\n",
      "|      encoder.transformer4.blocks.7.norm2.weight     |    192     |\n",
      "|       encoder.transformer4.blocks.7.norm2.bias      |    192     |\n",
      "|     encoder.transformer4.blocks.7.mlp.fc1.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.7.mlp.fc1.bias     |    768     |\n",
      "|     encoder.transformer4.blocks.7.mlp.fc2.weight    |   147456   |\n",
      "|      encoder.transformer4.blocks.7.mlp.fc2.bias     |    192     |\n",
      "|                    join.0.weight                    |   24576    |\n",
      "|                     join.0.bias                     |    128     |\n",
      "|                    join.2.weight                    |   16384    |\n",
      "|                     join.2.bias                     |    128     |\n",
      "|                    join.4.weight                    |   32768    |\n",
      "|                     join.4.bias                     |    256     |\n",
      "+-----------------------------------------------------+------------+\n",
      "Total Trainable Params: 7649612\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# from model2_seq import TransFuser\n",
    "from config_seq import GlobalConfig\n",
    "from prettytable import PrettyTable\n",
    "# from only_image_gps_transfuser import TransFuser2\n",
    "# from two_images_gps_transfuser import TransFuser3\n",
    "from model_efnet_gpt import TransFuser4\n",
    "from model_efnet_swin import SwinFuser1\n",
    "from torchvision import models\n",
    "\n",
    "device = \"cuda\"\n",
    "config = GlobalConfig()\n",
    "\n",
    "add_velocity =  1\n",
    "add_mask = 0\n",
    "enhanced = 1\n",
    "angle_norm = 1 \n",
    "custom_FoV_lidar = 1 \n",
    "filtered = 0\n",
    "add_seg = 0\n",
    "\n",
    "config.add_velocity = add_velocity\n",
    "config.add_mask = add_mask\n",
    "config.enhanced = enhanced\n",
    "config.angle_norm = angle_norm\n",
    "config.custom_FoV_lidar = custom_FoV_lidar\n",
    "config.filtered = filtered\n",
    "config.add_seg = add_seg\n",
    "\n",
    "\n",
    "# model = TransFuser4(config,device)\n",
    "model = SwinFuser1(config,device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "#for p in model.parameters():\n",
    "#    print(p.numel())\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(model)\n",
    "\n",
    "img_list = [torch.rand(2,3,config.crop,config.crop).to(device=device) for i in range(10)]\n",
    "gps_list = [torch.rand(2,5,2),torch.rand(2,5,2).to(device=device)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba2f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3453330/3699801469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfuse/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/V2V/swin_test/model_efnet_swin.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_list, gps_list)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mgps\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput\u001b[0m \u001b[0mgps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         '''\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0mfused_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfuse/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/V2V/swin_test/model_efnet_swin.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_list, gps_list)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgps_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mgps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgps_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'line412'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m#print(gps.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_cat)"
     ]
    }
   ],
   "source": [
    "out = model(img_list, gps_list)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c8a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
